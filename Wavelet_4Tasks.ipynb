{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "871b8018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import scipy.io\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import asarray\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from PIL import Image\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6160a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specified data and label directory\n",
    "data_dir = '/home/kiara/Desktop/EEG_Combined_Project/dataset/'\n",
    "# specifiying file names for dataset\n",
    "file_names = os.listdir(data_dir)\n",
    "file_names = [\"p4c2.mat\", \"p4c3.mat\", \"p4c4.mat\", \"p5c1.mat\", \"p5c2.mat\", \"p5c3.mat\", \"p5c4.mat\", \"p6c1.mat\", \"p6c2.mat\", \"p6c3.mat\", \"p6c4.mat\", \"p8c1.mat\", \"p8c2.mat\", \"p8c3.mat\", \"p8c4.mat\", \"p9c1.mat\", \"p9c2.mat\", \"p9c3.mat\", \"p9c4.mat\", \"p10c1.mat\", \"p10c2.mat\", \"p10c3.mat\", \"p10c4.mat\", \"p11c1.mat\", \"p11c2.mat\", \"p11c3.mat\", \"p11c4.mat\", \"p12c1.mat\", \"p12c2.mat\", \"p12c3.mat\", \"p12c4.mat\", \"p13c1.mat\", \"p13c2.mat\", \"p13c3.mat\", \"p13c4.mat\", \"p15c1.mat\", \"p15c2.mat\", \"p15c3.mat\", \"p15c4.mat\", \"p16c1.mat\", \"p16c2.mat\", \"p16c3.mat\", \"p16c4.mat\", \"p17c1.mat\", \"p17c2.mat\", \"p17c3.mat\", \"p17c4.mat\", \"p18c1.mat\", \"p18c2.mat\", \"p18c3.mat\", \"p18c4.mat\", \"p20c1.mat\", \"p20c2.mat\", \"p20c3.mat\", \"p20c4.mat\", \"p21c1.mat\", \"p21c2.mat\", \"p21c3.mat\", \"p21c4.mat\", \"p23c1.mat\", \"p23c2.mat\", \"p23c3.mat\", \"p23c4.mat\", \"p24c1.mat\", \"p24c2.mat\", \"p24c3.mat\", \"p24c4.mat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87cfe744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing a file for data extraction\n",
    "file_title = 16\n",
    "file_name1 = file_names[file_title] \n",
    "# generating random number for random selection of train and test set\n",
    "m = re.search('p(.+?)c', file_name1)\n",
    "if m:\n",
    "    random_state_value = int(m.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7fa625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining the data as numpy array\n",
    "load_file1 = os.path.join(data_dir, file_name1)\n",
    "data1 = scipy.io.loadmat(load_file1)\n",
    "my_data = data1['A']\n",
    "# obtaining timestamps at which the labels switch\n",
    "my_label1 = data1['latency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bcbf657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining timestamps at which the labels switch as a list with 0 as the initial value\n",
    "my_label1_shape = [0]\n",
    "for i in range(my_label1.shape[1]):\n",
    "    my_label1_shape.append(my_label1[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd035f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing a limiting value to facilitate label creation\n",
    "limiter = len(my_label1_shape)\n",
    "# obtaining dimensions of the data\n",
    "dims1 = my_data.shape[0]\n",
    "dims2 = my_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c6deb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing labels as a numpy array\n",
    "Y_train = np.zeros((len(my_label1_shape)), dtype = np.float32)\n",
    "label_zero = 0\n",
    "label_one = 1\n",
    "for i in range(0, limiter): # this runs from 0 to 17\n",
    "    if (i<(limiter-1)):\n",
    "        if (i==0 and (i != limiter-1)):\n",
    "            Y_train[i] = label_zero\n",
    "        \n",
    "        elif (i%2!=0 and i!=0 and i != (limiter-1)):\n",
    "            Y_train[i] = label_one\n",
    "        \n",
    "        elif ((i%2==0) and (i!=0) and (i != (limiter-1))):\n",
    "            Y_train[i] = label_zero\n",
    "            \n",
    "    elif (i >= (limiter-1)):\n",
    "        #print(\"this loop is executing\")\n",
    "        #print(i)\n",
    "        if (i%2==0):\n",
    "            Y_train[i] = label_zero\n",
    "        elif (i%2!=0):\n",
    "            Y_train[i] = label_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c41280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining a label list with end and begining time stamps included\n",
    "l1=my_label1_shape\n",
    "l1.append(dims2)\n",
    "# a list with durationof each time stamp for data\n",
    "res = [l1[i + 1] - l1[i] for i in range(len(l1)-1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff380504",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((Y_train.shape[0], dims1, max(res)), dtype = np.float32)\n",
    "# creating X_train with 0 padded to make all the columns of the same dimension\n",
    "for i in range(Y_train.shape[0]): # loop chalega 0 se 17 tak\n",
    "    if (i<(Y_train.shape[0]-1)):\n",
    "        arr1 = my_data[0:dims1, l1[i]:l1[i+1]]\n",
    "        to_pad = max(res) - arr1.shape[1]\n",
    "        X_add = np.pad(arr1, ((0,0),(0,to_pad)))\n",
    "        X_train[i] = X_add\n",
    "    elif (i==(Y_train.shape[0]-1)):\n",
    "        arr1 = my_data[0:dims1, l1[i]:dims2]\n",
    "        to_pad = max(res) - arr1.shape[1]\n",
    "        X_add = np.pad(arr1, ((0,0),(0,to_pad)))\n",
    "        X_train[i] = X_add\n",
    "    else:\n",
    "        print(\"----------------------------ERROR HAS OCCURED--------------------------------------\")\n",
    "        print(file_name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe2c6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import writer\n",
    "def append_list_as_row(file_name, list_of_elem):\n",
    "    # open file in append mode\n",
    "    with open(file_name, 'a+', newline='') as write_obj:\n",
    "        # creating writer object from csv module\n",
    "        csv_writer = writer(write_obj)\n",
    "        csv_writer.writerow(list_of_elem)\n",
    "        \n",
    "def wavelet_transform(input_data):\n",
    "    coeff, freq = pywt.cwt(input_data, X_train.shape[0], \"morl\")\n",
    "    return coeff  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7814b34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_X = wavelet_transform(X_train)\n",
    "x_train = my_X[0].reshape(my_X.shape[1], my_X.shape[2], my_X.shape[3], -1)\n",
    "\n",
    "# initializing log directory and model name\n",
    "m = re.search('p(.+?).m', file_name1)\n",
    "log_directory = 'Log_wavelet_'+str(file_name1)\n",
    "model_name = 'model_wavelet_'+str(file_name1)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b505451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing train test split\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(x_train, Y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2416d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (X_Train.shape[1], X_Train.shape[2], X_Train.shape[3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fafa6679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 963008)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               123265152 \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 123,298,433\n",
      "Trainable params: 123,298,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "model = Sequential()\n",
    "#l = [32, 64]\n",
    "'''\n",
    "l = [64, 128]\n",
    "model.add(Conv2D(l[0], (3, 3), input_shape=INPUT_SHAPE))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(l[0], (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(l[1], (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "'''\n",
    "\n",
    "\n",
    "model.add(Flatten(input_shape=INPUT_SHAPE))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03796b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience = 500, monitor = 'val_loss'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir = log_directory)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9cb585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "results = model.fit(X_Train, Y_Train, validation_split = 0.2, batch_size = 4, epochs = 200, verbose=0, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abbadd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# model evaluation on test data\n",
    "w_scores = model.evaluate(X_Test, Y_Test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ee54b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting test data values\n",
    "Y_hat = model.predict(X_Test)\n",
    "Y_pred = []\n",
    "for item in Y_hat:\n",
    "    if item>=(np.mean(Y_hat)):\n",
    "        Y_pred.append(1)\n",
    "    else:\n",
    "        Y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8e92d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining accuracy values\n",
    "correct = 0\n",
    "for i in range(len(Y_pred)):\n",
    "    if Y_Test[i] == Y_pred[i]:\n",
    "        correct += 1\n",
    "wavelet_accuracy = correct/len(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b94fc552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from Wavelet\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy from Wavelet\")\n",
    "print(wavelet_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c8116c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#row_contents = [file_name1, w_scores[1], wavelet_accuracy]\n",
    "#row_contents = ['Participant', 'Accuracy_Wavelet W Score', 'Calculated Accuracy']\n",
    "#append_list_as_row('/home/kiara/Desktop/Wavelet2.csv', row_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb138e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4229cd74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc0a99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
